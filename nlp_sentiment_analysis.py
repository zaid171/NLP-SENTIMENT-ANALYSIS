# -*- coding: utf-8 -*-
"""NLP sentiment_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VFuhHrzBxhhHkNsZYzTGMAexIBmLOZUC

## install and import
"""

!pip install pandas numpy scikit-learn matplotlib seaborn nltk wordcloud streamlit transformers

"""## install"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import nltk
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

"""## load dataset"""

df = pd.read_csv("/content/chatgpt_style_reviews_dataset.xlsx - Sheet1.csv")

print(df.head())
print(df.info())

"""## preprocessing"""

import re
nltk.download("stopwords")
stop_words = set(stopwords.words("english"))

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"[^a-z\s]", "", text)   # remove punctuation/numbers
    text = " ".join([word for word in text.split() if word not in stop_words])
    return text

df["clean_review"] = df["review"].apply(clean_text)

"""## EDA"""

sns.countplot(x="rating", data=df, palette="viridis")
plt.title("Distribution of Ratings")
plt.show()

"""## Word Cloud (Positive vs Negative)"""

pos_text = " ".join(df[df["rating"] >= 4]["clean_review"])
neg_text = " ".join(df[df["rating"] <= 2]["clean_review"])

WordCloud(width=800, height=400, background_color="white").generate(pos_text).to_image()
WordCloud(width=800, height=400, background_color="black").generate(neg_text).to_image()

"""## sentiment labelling"""

def get_sentiment(rating):
    if rating <= 2:
        return "Negative"
    elif rating == 3:
        return "Neutral"
    else:
        return "Positive"

df["sentiment"] = df["rating"].apply(get_sentiment)
print(df["sentiment"].value_counts())

"""## train and test split"""

X = df["clean_review"]
y = df["sentiment"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

vectorizer = TfidfVectorizer(max_features=5000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

display(df.head())

"""## train ML model"""

model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

y_pred = model.predict(X_test_vec)
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

"""## confusion matrix"""

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=model.classes_, yticklabels=model.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""## streamlit app.py"""

import streamlit as st
import joblib
import re
from sklearn.feature_extraction.text import TfidfVectorizer

# Load model + vectorizer
model = joblib.load("/content/sentiment_model.pkl")
vectorizer = joblib.load("/content/vectorizer.pkl")

def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z\s]", "", text)
    return text

st.title("ðŸ“Š AI Echo - Sentiment Analysis")
user_input = st.text_area("Enter a review:")

if st.button("Analyze"):
    if user_input.strip():
        cleaned = clean_text(user_input)
        vec = vectorizer.transform([cleaned])
        prediction = model.predict(vec)[0]
        st.success(f"Predicted Sentiment: {prediction}")

import joblib

# Save the trained model and vectorizer
joblib.dump(model, "sentiment_model.pkl")
joblib.dump(vectorizer, "vectorizer.pkl")

print("Model and vectorizer saved successfully!")

get_ipython().system('streamlit run app.py')

"""## extra work"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
import numpy as np

# Load the data
df = pd.read_csv('chatgpt_style_reviews_dataset.xlsx - Sheet1.csv')

# Set up the visualization style
plt.style.use('default')
fig = plt.figure(figsize=(20, 25))
plt.show

# 1. Distribution of review ratings
plt.subplot(5, 2, 1)
rating_counts = df['rating'].value_counts().sort_index()
colors = ['#ff6b6b', '#ffa726', '#ffee58', '#90caf9', '#66bb6a']
bars = plt.bar(rating_counts.index, rating_counts.values, color=colors, alpha=0.8)
plt.title('Distribution of Review Ratings', fontsize=14, fontweight='bold')
plt.xlabel('Rating (Stars)')
plt.ylabel('Number of Reviews')
plt.xticks(range(1, 6))
# Add value labels on bars
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{int(height)}', ha='center', va='bottom')

##2. Helpful reviews (threshold: >10 helpful votes)
plt.subplot(5, 2, 2)
threshold = 10
helpful_reviews = len(df[df['helpful_votes'] > threshold])
not_helpful_reviews = len(df) - helpful_reviews

plt.pie([helpful_reviews, not_helpful_reviews],
        labels=[f'Helpful (>10 votes)\n{helpful_reviews} reviews',
                f'Not Helpful (â‰¤10 votes)\n{not_helpful_reviews} reviews'],
        autopct='%1.1f%%', colors=['#4CAF50', '#FF9800'])
plt.title('Proportion of Helpful Reviews\n(Threshold: >10 helpful votes)', fontsize=14, fontweight='bold')

# 3. Most common keywords in positive vs negative reviews
# Prepare text data
positive_reviews = ' '.join(df[df['rating'] >= 4]['review'].astype(str))
negative_reviews = ' '.join(df[df['rating'] <= 2]['review'].astype(str))

# Positive reviews word cloud
plt.subplot(5, 2, 3)
wordcloud_positive = WordCloud(width=400, height=300,
                              background_color='white', colormap='viridis').generate(positive_reviews)
plt.imshow(wordcloud_positive, interpolation='bilinear')
plt.axis('off')
plt.title('Positive Reviews (4-5 stars)\nCommon Keywords', fontsize=12, fontweight='bold')

# Negative reviews word cloud
plt.subplot(5, 2, 4)
wordcloud_negative = WordCloud(width=400, height=300,
                              background_color='white', colormap='Reds').generate(negative_reviews)
plt.imshow(wordcloud_negative, interpolation='bilinear')
plt.axis('off')
plt.title('Negative Reviews (1-2 stars)\nCommon Keywords', fontsize=12, fontweight='bold')

# 4. Average rating over time
plt.subplot(5, 2, 5)
df['date'] = pd.to_datetime(df['date'])
monthly_avg = df.groupby(df['date'].dt.to_period('M'))['rating'].mean()
monthly_avg.index = monthly_avg.index.astype(str)

plt.plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2, markersize=6)
plt.title('Average Rating Over Time', fontsize=14, fontweight='bold')
plt.xlabel('Month')
plt.ylabel('Average Rating')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)

# 5. Ratings by platform
plt.subplot(5, 2, 6)
platform_ratings = df.groupby('platform')['rating'].mean().sort_values(ascending=False)
bars = plt.bar(platform_ratings.index, platform_ratings.values, color='skyblue', alpha=0.8)
plt.title('Average Rating by Platform', fontsize=14, fontweight='bold')
plt.xlabel('Platform')
plt.ylabel('Average Rating')
plt.ylim(0, 5)

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.2f}', ha='center', va='bottom')

# 6. Verified vs Non-verified users
plt.subplot(5, 2, 7)
verified_avg = df[df['verified_purchase'] == 'Yes']['rating'].mean()
non_verified_avg = df[df['verified_purchase'] == 'No']['rating'].mean()

plt.bar(['Verified\nUsers', 'Non-Verified\nUsers'], [verified_avg, non_verified_avg],
        color=['#2196F3', '#FFC107'], alpha=0.8)
plt.title('Average Rating: Verified vs Non-Verified Users', fontsize=14, fontweight='bold')
plt.ylabel('Average Rating')
plt.ylim(0, 5)

# Add value labels
plt.text(0, verified_avg + 0.1, f'{verified_avg:.2f}', ha='center', va='bottom', fontweight='bold')
plt.text(1, non_verified_avg + 0.1, f'{non_verified_avg:.2f}', ha='center', va='bottom', fontweight='bold')

# 7. Review length by rating
plt.subplot(5, 2, 8)
df['review_length'] = df['review'].str.split().str.len()
rating_length = df.groupby('rating')['review_length'].mean()

plt.bar(rating_length.index, rating_length.values, color='lightgreen', alpha=0.8)
plt.title('Average Review Length by Rating', fontsize=14, fontweight='bold')
plt.xlabel('Rating')
plt.ylabel('Average Word Count')
plt.xticks(range(1, 6))

# 8. Top locations by number of reviews
plt.subplot(5, 2, 9)
top_locations = df['location'].value_counts().head(5)
plt.barh(top_locations.index, top_locations.values, color='lightcoral', alpha=0.9)
plt.title('Top 5 Locations by Number of Reviews', fontsize=14, fontweight='bold')
plt.xlabel('Number of Reviews')
plt.gca().invert_yaxis()

# 9. Ratings by language
plt.subplot(5, 2, 10)
language_ratings = df.groupby('language')['rating'].mean().sort_values(ascending=False)
bars = plt.bar(language_ratings.index, language_ratings.values, color='plum', alpha=0.8)
plt.title('Average Rating by Language', fontsize=14, fontweight='bold')
plt.xlabel('Language')
plt.ylabel('Average Rating')
plt.ylim(0, 5)

for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{height:.2f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

"""## NLP"""

!pip install gensim